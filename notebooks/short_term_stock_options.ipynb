{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Set device for PyTorch\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "def predict(model, features_scaled, window_size, ticker, scaler, stock_data, enhanced_data, num_weeks=4):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    last_window = features_scaled[-window_size:]\n",
    "    last_price = float(stock_data['Close'].iloc[-1].iloc[0])\n",
    "    last_features = enhanced_data.iloc[-1]\n",
    "    \n",
    "    # Start from today\n",
    "    today = datetime.now()\n",
    "    # Calculate days until next Friday (4 is Friday)\n",
    "    days_until_friday = (4 - today.weekday()) % 7\n",
    "    if days_until_friday == 0 and today.hour >= 16:  # If it's Friday after market close\n",
    "        days_until_friday = 7\n",
    "    \n",
    "    next_friday = today + timedelta(days=days_until_friday)\n",
    "    # Generate the next 4 Fridays\n",
    "    prediction_dates = [next_friday + timedelta(weeks=i) for i in range(num_weeks)]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        current_window = torch.FloatTensor(last_window).unsqueeze(0).to(device)\n",
    "        current_price = last_price\n",
    "        \n",
    "        # Initialize volatility tracking\n",
    "        rolling_volatility = enhanced_data['10d_vol'].iloc[-1]  # Use 10-day vol for shorter term\n",
    "        rsi = enhanced_data['RSI'].iloc[-1]\n",
    "        stoch_rsi_k = enhanced_data['STOCH_RSI_K'].iloc[-1]\n",
    "        volume_trend = enhanced_data['Volume_Change'].iloc[-1]\n",
    "        \n",
    "        for i in range(len(prediction_dates)):\n",
    "            # Predict base percentage change\n",
    "            pct_change = model(current_window).item()\n",
    "            \n",
    "            # Add short-term volatility adjustments\n",
    "            vol_factor = rolling_volatility * np.random.normal(0, 1)\n",
    "            \n",
    "            # RSI-based adjustment (more volatile when RSI is at extremes)\n",
    "            rsi_factor = 0.0\n",
    "            if rsi > 70 or rsi < 30:\n",
    "                rsi_factor = (rsi - 50) / 50.0 * -0.01  # Mean reversion at extremes\n",
    "            \n",
    "            # StochRSI momentum adjustment\n",
    "            momentum_factor = (stoch_rsi_k - 50) / 50.0 * 0.005\n",
    "            \n",
    "            # Volume impact\n",
    "            volume_impact = np.sign(volume_trend) * min(abs(volume_trend), 0.01)\n",
    "            \n",
    "            # Combine all factors\n",
    "            adjusted_pct_change = pct_change + vol_factor + rsi_factor + momentum_factor + volume_impact\n",
    "            \n",
    "            # Calculate predicted price\n",
    "            predicted_price = current_price * (1 + adjusted_pct_change)\n",
    "            predictions.append(predicted_price)\n",
    "            \n",
    "            # Update for next prediction\n",
    "            current_price = predicted_price\n",
    "            \n",
    "            # Update indicators\n",
    "            rolling_volatility = rolling_volatility * 0.8 + abs(adjusted_pct_change) * 0.2\n",
    "            rsi = max(0, min(100, rsi + adjusted_pct_change * 20))\n",
    "            stoch_rsi_k = max(0, min(100, stoch_rsi_k + adjusted_pct_change * 15))\n",
    "            volume_trend = volume_trend * 0.7 + np.random.normal(0, 0.1)\n",
    "            \n",
    "            # Create new window by shifting\n",
    "            new_window = current_window.clone()\n",
    "            new_window[0, :-1, :] = new_window[0, 1:, :]\n",
    "            \n",
    "            # Update features with more realistic variations\n",
    "            new_features = last_features.copy()\n",
    "            new_features['Close'] = predicted_price\n",
    "            new_features['Open'] = predicted_price * (1 + np.random.normal(0, 0.005))\n",
    "            new_features['High'] = predicted_price * (1 + abs(np.random.normal(0, 0.01)))\n",
    "            new_features['Low'] = predicted_price * (1 - abs(np.random.normal(0, 0.01)))\n",
    "            new_features['Volume'] = new_features['Volume'] * (1 + volume_trend)\n",
    "            \n",
    "            # Update technical indicators\n",
    "            new_features['10d_vol'] = rolling_volatility\n",
    "            new_features['RSI'] = rsi\n",
    "            new_features['STOCH_RSI_K'] = stoch_rsi_k\n",
    "            new_features['Volume_Change'] = volume_trend\n",
    "            \n",
    "            # Scale the new features\n",
    "            scaled_new_features = scaler.transform(new_features.values.reshape(1, -1))[0]\n",
    "            new_window[0, -1, :] = torch.FloatTensor(scaled_new_features).to(device)\n",
    "            current_window = new_window\n",
    "\n",
    "    # Create DataFrame with more detailed predictions\n",
    "    prediction_df = pd.DataFrame({\n",
    "        'Date': prediction_dates,\n",
    "        'Predicted Price': predictions,\n",
    "        'Pct_Change': [(p/last_price - 1)*100 for p in predictions],\n",
    "        'Volatility': [rolling_volatility * 100] * len(predictions),\n",
    "        'RSI': [rsi] * len(predictions),\n",
    "        'StochRSI_K': [stoch_rsi_k] * len(predictions)\n",
    "    })\n",
    "    \n",
    "    print(\"\\nPredictions for upcoming Fridays:\")\n",
    "    print(prediction_df.to_string(float_format=lambda x: '{:.2f}'.format(x)))\n",
    "    \n",
    "    # Enhanced visualization\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))\n",
    "    \n",
    "    # Price plot\n",
    "    ax1.plot(stock_data.index[-20:], stock_data['Close'][-20:], label='Historical')\n",
    "    ax1.plot(prediction_dates, predictions, label='Predicted', linestyle='--')\n",
    "    ax1.set_title(f'{ticker} Stock Price Prediction (Weekly Friday Closes)')\n",
    "    ax1.set_xlabel('Date')\n",
    "    ax1.set_ylabel('Price')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "    \n",
    "    # Technical indicators plot\n",
    "    ax2.plot(prediction_dates, prediction_df['RSI'], label='RSI', color='blue')\n",
    "    ax2.plot(prediction_dates, prediction_df['StochRSI_K'], label='StochRSI_K', color='green')\n",
    "    ax2.plot(prediction_dates, prediction_df['Volatility'], label='Volatility %', color='red')\n",
    "    ax2.set_title('Technical Indicators')\n",
    "    ax2.set_xlabel('Date')\n",
    "    ax2.set_ylabel('Value')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return prediction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "import constants\n",
    "from utils.models.train import train\n",
    "from utils.models.save import save\n",
    "from utils.models.load import load\n",
    "from utils.stocks.get_swing_candidates import get_swing_candidates\n",
    "from utils.stocks.download_stock_data import download_stock_data\n",
    "from utils.stocks.add_short_term_stock_features import add_short_term_stock_features\n",
    "from utils.training.short_term_growth import short_term_growth\n",
    "\n",
    "model_name = \"stock_options_high_interest_model\"\n",
    "\n",
    "# Try to load existing model first\n",
    "model, scaler, last_data = load(model_name)\n",
    "\n",
    "if model is None:\n",
    "    print(f\"Training new model.\")\n",
    "    # these tickers are used for training\n",
    "    # they create the model baseline that we want to beat or match\n",
    "    stock_options_swing_candidates = get_swing_candidates()\n",
    "\n",
    "    model, scaler = short_term_growth(stock_options_swing_candidates, model_name)\n",
    "    # Verify we have a NEW model and scaler before proceeding\n",
    "    if model is None or scaler is None:\n",
    "        print(\"No valid model and scaler available. Cannot proceed with predictions.\")\n",
    "        exit()\n",
    "\n",
    "# Verify we have a PRE_LOADED model and scaler before proceeding\n",
    "if model is None or scaler is None:\n",
    "    print(\"No valid model and scaler available. Cannot proceed with predictions.\")\n",
    "    exit()\n",
    "\n",
    "# for analysis, these tickers use the model for prediction!\n",
    "# this is where you set your stock symbols you want to predict on\n",
    "tickers = [\"LCID\", \"GME\", \"AMC\", \"RIOT\", \"MARA\", \"PLTR\", \"NVAX\", \"EXPE\", \"UPST\", \"FUBO\", \"TSLA\", \"NIO\", \"BIDU\", \"SPCE\", \"MRNA\", \"DKNG\", \"SOFI\", \"INTC\", \"LULU\", \"COIN\", \"PLUG\", \"BABA\", \"FSLY\", \"WORK\", \"STPK\", \"SLGG\", \"SENS\", \"CLSK\", \"VANW\", \"HOOD\"]\n",
    "\n",
    "# Run the model for each ticker\n",
    "for ticker in tickers:\n",
    "    print(f\"\\nGenerating predictions for {ticker}\")\n",
    "    stock_data = download_stock_data(ticker, \n",
    "                                    datetime.now() - timedelta(days=30),\n",
    "                                    datetime.now())\n",
    "    enhanced_data = add_short_term_stock_features(stock_data, ticker)\n",
    "    \n",
    "    # Define available features (make sure this matches your training features)\n",
    "    short_term_growth_features = constants.SHORT_TERM_STOCK_FEATURES\n",
    "        \n",
    "    features = enhanced_data[short_term_growth_features].values\n",
    "    if features.size == 0:\n",
    "        raise ValueError(\"No valid features extracted\")\n",
    "    features_scaled = scaler.transform(features)\n",
    "    predictions = predict(model, features_scaled, 20, ticker, scaler, stock_data, enhanced_data, num_weeks=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
